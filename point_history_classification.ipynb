{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 15:35:17.427286: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-29 15:35:17.429929: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 15:35:17.483235: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-29 15:35:17.484648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 15:35:18.434620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/point_history_classifier/point_history.csv'\n",
    "model_save_path = 'model/point_history_classifier/point_history_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 入力長"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 16\n",
    "DIMENSION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (TIME_STEPS * DIMENSION) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_lstm = False\n",
    "model = None\n",
    "\n",
    "if use_lstm:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "        tf.keras.layers.Reshape((TIME_STEPS, DIMENSION), input_shape=(TIME_STEPS * DIMENSION, )), \n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.LSTM(16, input_shape=[TIME_STEPS, DIMENSION]),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "else:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(24, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                792       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 24)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                250       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,075\n",
      "Trainable params: 1,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 1.0862 - accuracy: 0.3516 \n",
      "Epoch 1: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 1s 7ms/step - loss: 1.0769 - accuracy: 0.3749 - val_loss: 1.0486 - val_accuracy: 0.4341\n",
      "Epoch 2/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 1.0385 - accuracy: 0.4247\n",
      "Epoch 2: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0396 - accuracy: 0.4214 - val_loss: 1.0164 - val_accuracy: 0.4740\n",
      "Epoch 3/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 1.0079 - accuracy: 0.4516\n",
      "Epoch 3: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.4516 - val_loss: 0.9876 - val_accuracy: 0.5406\n",
      "Epoch 4/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.9817 - accuracy: 0.4683\n",
      "Epoch 4: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9797 - accuracy: 0.4702 - val_loss: 0.9526 - val_accuracy: 0.5843\n",
      "Epoch 5/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.9465 - accuracy: 0.5016\n",
      "Epoch 5: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9457 - accuracy: 0.5004 - val_loss: 0.9114 - val_accuracy: 0.6242\n",
      "Epoch 6/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.9087 - accuracy: 0.5458\n",
      "Epoch 6: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9082 - accuracy: 0.5471 - val_loss: 0.8670 - val_accuracy: 0.6407\n",
      "Epoch 7/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.8728 - accuracy: 0.6317\n",
      "Epoch 7: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8724 - accuracy: 0.6323 - val_loss: 0.8207 - val_accuracy: 0.8878\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.8369 - accuracy: 0.7377\n",
      "Epoch 8: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8369 - accuracy: 0.7377 - val_loss: 0.7728 - val_accuracy: 0.9119\n",
      "Epoch 9/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.7935 - accuracy: 0.7599\n",
      "Epoch 9: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7952 - accuracy: 0.7563 - val_loss: 0.7216 - val_accuracy: 0.9265\n",
      "Epoch 10/1000\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 0.7621 - accuracy: 0.7698\n",
      "Epoch 10: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.7576 - accuracy: 0.7688 - val_loss: 0.6755 - val_accuracy: 0.9202\n",
      "Epoch 11/1000\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.7309 - accuracy: 0.7693\n",
      "Epoch 11: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.7707 - val_loss: 0.6280 - val_accuracy: 0.9347\n",
      "Epoch 12/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.6973 - accuracy: 0.7741\n",
      "Epoch 12: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.7732 - val_loss: 0.5863 - val_accuracy: 0.9322\n",
      "Epoch 13/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.8263 - accuracy: 0.6719\n",
      "Epoch 13: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.7806 - val_loss: 0.5482 - val_accuracy: 0.9347\n",
      "Epoch 14/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.6631 - accuracy: 0.7891\n",
      "Epoch 14: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7855 - val_loss: 0.5168 - val_accuracy: 0.9309\n",
      "Epoch 15/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.5966 - accuracy: 0.8125\n",
      "Epoch 15: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.7908 - val_loss: 0.4879 - val_accuracy: 0.9322\n",
      "Epoch 16/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.5913 - accuracy: 0.7969\n",
      "Epoch 16: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7965 - val_loss: 0.4607 - val_accuracy: 0.9373\n",
      "Epoch 17/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.5760 - accuracy: 0.7981\n",
      "Epoch 17: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7975 - val_loss: 0.4397 - val_accuracy: 0.9423\n",
      "Epoch 18/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.5595 - accuracy: 0.8203\n",
      "Epoch 18: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7992 - val_loss: 0.4237 - val_accuracy: 0.9417\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.8052\n",
      "Epoch 19: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.8052 - val_loss: 0.4061 - val_accuracy: 0.9436\n",
      "Epoch 20/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.5309 - accuracy: 0.8176\n",
      "Epoch 20: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.8168 - val_loss: 0.3916 - val_accuracy: 0.9436\n",
      "Epoch 21/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.6324 - accuracy: 0.7031\n",
      "Epoch 21: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.8123 - val_loss: 0.3791 - val_accuracy: 0.9499\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.8219\n",
      "Epoch 22: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8219 - val_loss: 0.3686 - val_accuracy: 0.9487\n",
      "Epoch 23/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.5241 - accuracy: 0.8074\n",
      "Epoch 23: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.8094 - val_loss: 0.3628 - val_accuracy: 0.9493\n",
      "Epoch 24/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.4966 - accuracy: 0.8226\n",
      "Epoch 24: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8223 - val_loss: 0.3525 - val_accuracy: 0.9512\n",
      "Epoch 25/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.5044 - accuracy: 0.8047\n",
      "Epoch 25: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8297 - val_loss: 0.3399 - val_accuracy: 0.9480\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.8206\n",
      "Epoch 26: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.8206 - val_loss: 0.3312 - val_accuracy: 0.9506\n",
      "Epoch 27/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.4295 - accuracy: 0.8438\n",
      "Epoch 27: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8284 - val_loss: 0.3257 - val_accuracy: 0.9480\n",
      "Epoch 28/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.4632 - accuracy: 0.8324\n",
      "Epoch 28: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.8331 - val_loss: 0.3154 - val_accuracy: 0.9499\n",
      "Epoch 29/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.4610 - accuracy: 0.8329\n",
      "Epoch 29: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.8337 - val_loss: 0.3096 - val_accuracy: 0.9531\n",
      "Epoch 30/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.4805 - accuracy: 0.8281\n",
      "Epoch 30: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.8343 - val_loss: 0.3042 - val_accuracy: 0.9525\n",
      "Epoch 31/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.8327\n",
      "Epoch 31: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8335 - val_loss: 0.3003 - val_accuracy: 0.9480\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8430\n",
      "Epoch 32: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.8430 - val_loss: 0.2946 - val_accuracy: 0.9493\n",
      "Epoch 33/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.4237 - accuracy: 0.8435\n",
      "Epoch 33: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8449 - val_loss: 0.2875 - val_accuracy: 0.9493\n",
      "Epoch 34/1000\n",
      "27/37 [====================>.........] - ETA: 0s - loss: 0.4255 - accuracy: 0.8455\n",
      "Epoch 34: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8468 - val_loss: 0.2796 - val_accuracy: 0.9493\n",
      "Epoch 35/1000\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.4168 - accuracy: 0.8583\n",
      "Epoch 35: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8533 - val_loss: 0.2707 - val_accuracy: 0.9512\n",
      "Epoch 36/1000\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.4117 - accuracy: 0.8430\n",
      "Epoch 36: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8421 - val_loss: 0.2710 - val_accuracy: 0.9474\n",
      "Epoch 37/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.4093 - accuracy: 0.8516\n",
      "Epoch 37: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8525 - val_loss: 0.2643 - val_accuracy: 0.9487\n",
      "Epoch 38/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.4092 - accuracy: 0.8508\n",
      "Epoch 38: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8538 - val_loss: 0.2585 - val_accuracy: 0.9493\n",
      "Epoch 39/1000\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 0.4081 - accuracy: 0.8504\n",
      "Epoch 39: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8504 - val_loss: 0.2549 - val_accuracy: 0.9518\n",
      "Epoch 40/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3851 - accuracy: 0.8617\n",
      "Epoch 40: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.8603 - val_loss: 0.2481 - val_accuracy: 0.9493\n",
      "Epoch 41/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.3875 - accuracy: 0.8500\n",
      "Epoch 41: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8489 - val_loss: 0.2520 - val_accuracy: 0.9461\n",
      "Epoch 42/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.4002 - accuracy: 0.8540\n",
      "Epoch 42: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8550 - val_loss: 0.2440 - val_accuracy: 0.9499\n",
      "Epoch 43/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.3981 - accuracy: 0.8585\n",
      "Epoch 43: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8595 - val_loss: 0.2448 - val_accuracy: 0.9512\n",
      "Epoch 44/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8613\n",
      "Epoch 44: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3907 - accuracy: 0.8597 - val_loss: 0.2407 - val_accuracy: 0.9512\n",
      "Epoch 45/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3862 - accuracy: 0.8624\n",
      "Epoch 45: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3869 - accuracy: 0.8628 - val_loss: 0.2399 - val_accuracy: 0.9518\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8574\n",
      "Epoch 46: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8574 - val_loss: 0.2318 - val_accuracy: 0.9512\n",
      "Epoch 47/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3838 - accuracy: 0.8518\n",
      "Epoch 47: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8548 - val_loss: 0.2289 - val_accuracy: 0.9506\n",
      "Epoch 48/1000\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 0.3671 - accuracy: 0.8594\n",
      "Epoch 48: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8571 - val_loss: 0.2255 - val_accuracy: 0.9487\n",
      "Epoch 49/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3691 - accuracy: 0.8662\n",
      "Epoch 49: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8669 - val_loss: 0.2260 - val_accuracy: 0.9468\n",
      "Epoch 50/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3598 - accuracy: 0.8624\n",
      "Epoch 50: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8620 - val_loss: 0.2147 - val_accuracy: 0.9525\n",
      "Epoch 51/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.3633 - accuracy: 0.8658\n",
      "Epoch 51: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3630 - accuracy: 0.8667 - val_loss: 0.2158 - val_accuracy: 0.9487\n",
      "Epoch 52/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3513 - accuracy: 0.8716\n",
      "Epoch 52: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8707 - val_loss: 0.2138 - val_accuracy: 0.9506\n",
      "Epoch 53/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.3691 - accuracy: 0.8613\n",
      "Epoch 53: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8620 - val_loss: 0.2152 - val_accuracy: 0.9499\n",
      "Epoch 54/1000\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 0.3422 - accuracy: 0.8760\n",
      "Epoch 54: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8749 - val_loss: 0.2117 - val_accuracy: 0.9493\n",
      "Epoch 55/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3540 - accuracy: 0.8722\n",
      "Epoch 55: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8719 - val_loss: 0.2099 - val_accuracy: 0.9493\n",
      "Epoch 56/1000\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 0.3530 - accuracy: 0.8702\n",
      "Epoch 56: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8709 - val_loss: 0.2078 - val_accuracy: 0.9493\n",
      "Epoch 57/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.3583 - accuracy: 0.8717\n",
      "Epoch 57: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8696 - val_loss: 0.2055 - val_accuracy: 0.9487\n",
      "Epoch 58/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.3303 - accuracy: 0.8745\n",
      "Epoch 58: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8755 - val_loss: 0.2103 - val_accuracy: 0.9417\n",
      "Epoch 59/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.3487 - accuracy: 0.8718\n",
      "Epoch 59: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8728 - val_loss: 0.1969 - val_accuracy: 0.9506\n",
      "Epoch 60/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3534 - accuracy: 0.8768\n",
      "Epoch 60: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8753 - val_loss: 0.1975 - val_accuracy: 0.9512\n",
      "Epoch 61/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3314 - accuracy: 0.8808\n",
      "Epoch 61: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8798 - val_loss: 0.1954 - val_accuracy: 0.9487\n",
      "Epoch 62/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3367 - accuracy: 0.8734\n",
      "Epoch 62: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8734 - val_loss: 0.1995 - val_accuracy: 0.9449\n",
      "Epoch 63/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3495 - accuracy: 0.8697\n",
      "Epoch 63: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8730 - val_loss: 0.1939 - val_accuracy: 0.9531\n",
      "Epoch 64/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.3274 - accuracy: 0.8781\n",
      "Epoch 64: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8802 - val_loss: 0.1906 - val_accuracy: 0.9474\n",
      "Epoch 65/1000\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 0.3363 - accuracy: 0.8773\n",
      "Epoch 65: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8783 - val_loss: 0.1919 - val_accuracy: 0.9480\n",
      "Epoch 66/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3246 - accuracy: 0.8789\n",
      "Epoch 66: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8770 - val_loss: 0.1911 - val_accuracy: 0.9461\n",
      "Epoch 67/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3439 - accuracy: 0.8706\n",
      "Epoch 67: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8726 - val_loss: 0.1906 - val_accuracy: 0.9468\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.8757\n",
      "Epoch 68: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8757 - val_loss: 0.1898 - val_accuracy: 0.9480\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.8749\n",
      "Epoch 69: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8749 - val_loss: 0.1869 - val_accuracy: 0.9512\n",
      "Epoch 70/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.3202 - accuracy: 0.8843\n",
      "Epoch 70: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8867 - val_loss: 0.1842 - val_accuracy: 0.9537\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8726\n",
      "Epoch 71: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8726 - val_loss: 0.1842 - val_accuracy: 0.9512\n",
      "Epoch 72/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3450 - accuracy: 0.8768\n",
      "Epoch 72: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8760 - val_loss: 0.1877 - val_accuracy: 0.9493\n",
      "Epoch 73/1000\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 0.3338 - accuracy: 0.8738\n",
      "Epoch 73: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.8766 - val_loss: 0.1877 - val_accuracy: 0.9480\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8774\n",
      "Epoch 74: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8774 - val_loss: 0.1859 - val_accuracy: 0.9506\n",
      "Epoch 75/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.4154 - accuracy: 0.8594\n",
      "Epoch 75: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3351 - accuracy: 0.8787 - val_loss: 0.1812 - val_accuracy: 0.9531\n",
      "Epoch 76/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8815\n",
      "Epoch 76: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.8810 - val_loss: 0.1854 - val_accuracy: 0.9487\n",
      "Epoch 77/1000\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.8838\n",
      "Epoch 77: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8838 - val_loss: 0.1805 - val_accuracy: 0.9512\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.8878\n",
      "Epoch 78: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8878 - val_loss: 0.1826 - val_accuracy: 0.9487\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3344 - accuracy: 0.8804\n",
      "Epoch 79: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8804 - val_loss: 0.1827 - val_accuracy: 0.9525\n",
      "Epoch 80/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2918 - accuracy: 0.8906\n",
      "Epoch 80: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8842 - val_loss: 0.1833 - val_accuracy: 0.9512\n",
      "Epoch 81/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3168 - accuracy: 0.8906\n",
      "Epoch 81: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3161 - accuracy: 0.8874 - val_loss: 0.1834 - val_accuracy: 0.9499\n",
      "Epoch 82/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2525 - accuracy: 0.9453\n",
      "Epoch 82: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8823 - val_loss: 0.1794 - val_accuracy: 0.9474\n",
      "Epoch 83/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.8817\n",
      "Epoch 83: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8817 - val_loss: 0.1791 - val_accuracy: 0.9487\n",
      "Epoch 84/1000\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.3156 - accuracy: 0.8812\n",
      "Epoch 84: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8798 - val_loss: 0.1882 - val_accuracy: 0.9449\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.8897\n",
      "Epoch 85: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8897 - val_loss: 0.1792 - val_accuracy: 0.9461\n",
      "Epoch 86/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3163 - accuracy: 0.8672\n",
      "Epoch 86: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8823 - val_loss: 0.1749 - val_accuracy: 0.9474\n",
      "Epoch 87/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3248 - accuracy: 0.8906\n",
      "Epoch 87: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8730 - val_loss: 0.1748 - val_accuracy: 0.9550\n",
      "Epoch 88/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3696 - accuracy: 0.8594\n",
      "Epoch 88: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8793 - val_loss: 0.1757 - val_accuracy: 0.9531\n",
      "Epoch 89/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2975 - accuracy: 0.9062\n",
      "Epoch 89: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8882 - val_loss: 0.1763 - val_accuracy: 0.9512\n",
      "Epoch 90/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8750\n",
      "Epoch 90: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8793 - val_loss: 0.1778 - val_accuracy: 0.9480\n",
      "Epoch 91/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2996 - accuracy: 0.8984\n",
      "Epoch 91: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8791 - val_loss: 0.1806 - val_accuracy: 0.9474\n",
      "Epoch 92/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3374 - accuracy: 0.8750\n",
      "Epoch 92: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8850 - val_loss: 0.1761 - val_accuracy: 0.9480\n",
      "Epoch 93/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3110 - accuracy: 0.8594\n",
      "Epoch 93: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8867 - val_loss: 0.1698 - val_accuracy: 0.9531\n",
      "Epoch 94/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8882\n",
      "Epoch 94: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8884 - val_loss: 0.1704 - val_accuracy: 0.9506\n",
      "Epoch 95/1000\n",
      "29/37 [======================>.......] - ETA: 0s - loss: 0.3174 - accuracy: 0.8844\n",
      "Epoch 95: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8840 - val_loss: 0.1798 - val_accuracy: 0.9455\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.8905\n",
      "Epoch 96: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8905 - val_loss: 0.1717 - val_accuracy: 0.9544\n",
      "Epoch 97/1000\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 0.3050 - accuracy: 0.8853\n",
      "Epoch 97: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8817 - val_loss: 0.1838 - val_accuracy: 0.9404\n",
      "Epoch 98/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3155 - accuracy: 0.8828\n",
      "Epoch 98: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8872 - val_loss: 0.1758 - val_accuracy: 0.9480\n",
      "Epoch 99/1000\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 0.2957 - accuracy: 0.8908\n",
      "Epoch 99: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8901 - val_loss: 0.1761 - val_accuracy: 0.9430\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8852\n",
      "Epoch 100: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3046 - accuracy: 0.8852 - val_loss: 0.1707 - val_accuracy: 0.9512\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3149 - accuracy: 0.8804\n",
      "Epoch 101: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8804 - val_loss: 0.1797 - val_accuracy: 0.9461\n",
      "Epoch 102/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3082 - accuracy: 0.8828\n",
      "Epoch 102: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8806 - val_loss: 0.1702 - val_accuracy: 0.9525\n",
      "Epoch 103/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3647 - accuracy: 0.8516\n",
      "Epoch 103: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8869 - val_loss: 0.1699 - val_accuracy: 0.9499\n",
      "Epoch 104/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2018 - accuracy: 0.9141\n",
      "Epoch 104: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8812 - val_loss: 0.1788 - val_accuracy: 0.9411\n",
      "Epoch 105/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3010 - accuracy: 0.8750\n",
      "Epoch 105: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8935 - val_loss: 0.1699 - val_accuracy: 0.9518\n",
      "Epoch 106/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2841 - accuracy: 0.8750\n",
      "Epoch 106: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8840 - val_loss: 0.1709 - val_accuracy: 0.9506\n",
      "Epoch 107/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2412 - accuracy: 0.9219\n",
      "Epoch 107: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3120 - accuracy: 0.8831 - val_loss: 0.1795 - val_accuracy: 0.9385\n",
      "Epoch 108/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3702 - accuracy: 0.8594\n",
      "Epoch 108: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8912 - val_loss: 0.1701 - val_accuracy: 0.9512\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.8888\n",
      "Epoch 109: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.8888 - val_loss: 0.1841 - val_accuracy: 0.9341\n",
      "Epoch 110/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2919 - accuracy: 0.8906\n",
      "Epoch 110: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8869 - val_loss: 0.1807 - val_accuracy: 0.9398\n",
      "Epoch 111/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.3232 - accuracy: 0.8594\n",
      "Epoch 111: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8848 - val_loss: 0.1842 - val_accuracy: 0.9360\n",
      "Epoch 112/1000\n",
      " 1/37 [..............................] - ETA: 0s - loss: 0.2202 - accuracy: 0.9219\n",
      "Epoch 112: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8863 - val_loss: 0.1776 - val_accuracy: 0.9404\n",
      "Epoch 113/1000\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.8845\n",
      "Epoch 113: saving model to model/point_history_classifier/point_history_classifier.hdf5\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8855 - val_loss: 0.1729 - val_accuracy: 0.9474\n",
      "Epoch 113: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f699c153c40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "[2.0449679e-15 1.3472976e-02 9.8652703e-01]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 混同行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       397\n",
      "           1       0.96      0.90      0.93       612\n",
      "           2       0.91      0.96      0.93       569\n",
      "\n",
      "    accuracy                           0.95      1578\n",
      "   macro avg       0.95      0.95      0.95      1578\n",
      "weighted avg       0.95      0.95      0.95      1578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite用のモデルへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_save_path = 'model/point_history_classifier/point_history_classifier.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 15:35:34.015096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,32]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-06-29 15:35:34.064701: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-29 15:35:34.077920: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_1' with dtype float and shape [?,32]\n",
      "\t [[{{node input_1}}]]\n",
      "2023-06-29 15:35:34.100184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-29 15:35:34.112522: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-29 15:35:34.132931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-29 15:35:34.199025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_agnleif/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 15:35:34.248380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-29 15:35:34.277944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-29 15:35:34.719162: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-06-29 15:35:34.719196: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-06-29 15:35:34.719559: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp_agnleif\n",
      "2023-06-29 15:35:34.720419: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-29 15:35:34.720436: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp_agnleif\n",
      "2023-06-29 15:35:34.723256: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-06-29 15:35:34.723929: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-06-29 15:35:34.741967: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp_agnleif\n",
      "2023-06-29 15:35:34.747835: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 28278 microseconds.\n",
      "2023-06-29 15:35:34.762011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6388"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 32], dtype=int32), 'shape_signature': array([-1, 32], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 µs, sys: 24 µs, total: 167 µs\n",
      "Wall time: 138 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0449677e-15 1.3472989e-02 9.8652703e-01]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
